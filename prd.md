# RAG Agent PRD (Product Requirements Document)

## 1. 개요
- 목적: Appendix의 예시 코드와 사내 인프라를 참고하여, 엔터프라이즈 문서 검색·요약·질의응답을 제공하는 RAG(Retrieval-Augmented Generation) 에이전트를 설계/구현한다.
- 기대효과: 검색 품질 향상, 생성 신뢰도 제고, 사내 권한 체계 연동, 운영/관측 용이성.
- 참조: `appendix/internal_llm.py`, `appendix/rag_input.py`, `appendix/rag_retrieve.py`

## 2. 배경과 문제정의
- 사내 문서/지식이 시스템/부서별로 분산되어 있어 검색과 회수의 비용이 큼.
- 일반 LLM의 환각(Hallucination) 리스크로 인해 출처 기반의 답변 근거가 필요.
- 권한 체계를 무시한 응답은 보안 리스크를 유발.

## 3. 대상 사용자
- 일반 임직원: 사내 문서 기반 질의응답, 요약, 설명.
- 분석가/PM/개발자: 특정 도메인 지식 검색·인용, 코드/가이드 서치.
- 운영자: 인덱스 관리, 로그 관찰, 성능/품질 개선.

## 4. 범위(Scope)
- 문서 적재 API 연동: `POST /insert-doc` (Appendix `rag_input.py` 참고)
- 검색 API 연동: `POST /retrieve-rrf`, `POST /retrieve-bm25`, `POST /retrieve-knn`, `POST /retrieve-cc` (Appendix `rag_retrieve.py` 참고)
 - 검색 API 연동: `POST /retrieve-rrf`, `POST /retrieve-bm25`, `POST /retrieve-knn`, `POST /retrieve-cc` (응답 포맷은 Elasticsearch 스타일)
- RAG 파이프라인: 쿼리 전처리 → 검색 → 근거 정제 → LLM 생성.
- 권한 기반 필터링: `permission_groups` 기반 접근 제어.
- 청킹 정책: 고정 크기 등 정책 설정(`chunk_factor`).
- LLM 백엔드 연동: `internal_llm.py` 참조(모델/엔드포인트/헤더 설정).
- LangGraph 기반 에이전트 오케스트레이션(쿼리 재작성→복수 리트리버 병렬→재랭킹→생성→자기평가/수정).
- 사용자 피드백 수집/반영(좋아요/싫어요, 사유/수정안) 및 실험/지표.
 - FastAPI 기반 Web UI: 질의 입력, 결과/근거 표시, 피드백 제출(최소 기능).
- 문서 입력(최소): Confluence DC 페이지/첨부 단발 수집, 로컬 파일 업로드.
- 문서 파싱: `docling`으로 PDF/DOCX/PPTX/XLSX 등 일반 문서를 구조 보존 형태로 파싱.
- 메타 보강: LLM이 `additional_field`를 자율 생성(주제/키워드/요약/언어/민감도 태그 등).
 - 업서트 제약: RAG insert payload는 flat structure만 허용(중첩 JSON 금지; `additional_field`는 문자열 등 단일 필드 사용).
 - Confluence 수집: pageId 기반 단발 수집(페이지 단위), Confluence 호출은 SSL 인증 비활성화(verify=False, MVP 제한).

## 5. 비범위(Out of Scope)
- 문서 크롤러/ETL 파이프라인 구현 전부.
- 고급 피드백 루프(예: Reinforcement from Human Feedback).
- 레이아웃/표/이미지 OCR 파이프라인 심화 구현.
 - 보안/인증(SSO, JWT, RBAC) 및 감사 강화 기능: MVP 단계에서는 미적용.
 - 관리자 대시보드/운영 자동화 고급 기능.
 - 대규모 크롤러/스케줄러/증분 동기화는 후속 단계에서.

## 6. 사용자 스토리(요구사항)
- 사용자로서, 키워드/자연어 질문을 입력하면 상위 관련 문서 근거와 함께 답을 받고 싶다.
- 사용자로서, 내 권한 범위 내 문서만 검색 결과에 포함되길 원한다.
- 사용자로서, 결과가 부정확할 때 피드백(좋아요/싫어요, 이유, 정답 제안)을 남기고 향후 응답 개선에 반영되길 원한다.
- 운영자로서, 인덱스에 문서를 적재/갱신/삭제하고 상태를 모니터링하고 싶다.
- 운영자로서, 검색 리콜/정밀도 및 응답 지연을 추적하고 싶다.
- 운영자로서, 프롬프트/리트리버/재랭커 설정에 대해 A/B 실험을 수행하고 성과를 비교하고 싶다.

## 7. 기능 요구사항
- 검색 엔진 통합: BM25, kNN, CC(컬럼 조건), RRF 융합 지원.
- 인덱싱: 문서 메타/콘텐츠 입력, 청킹 정책(`chunk_size`, `overlap`, `separator`).
- 필터/권한: `permission_groups` 기반 필터, 사내 인증 헤더 연동.
- 생성: 근거(문서 스니펫) 기반 LLM 응답과 출처 표기.
- 구성: 인덱스명/리트리버 파라미터/모델을 설정으로 제어.
- 오류 처리: API 실패/LLM 타임아웃/빈 결과 시 Fallback 전략.
- LangGraph 에이전트: 노드(쿼리 재작성, 복수 리트리버, 재랭킹, 생성, 자기평가/수정)로 파이프라인 구성 및 체크포인터 지원.
- 성능 기법: 다중 쿼리 확장, 하이브리드 검색(BM25+벡터), MMR/중복제거, 크로스인코더 재랭킹, RRF, 컨텍스트 압축/요약, 의미/응답 캐시, PRF(의사관련 피드백), 동적 청킹.
- 사용자 피드백: 응답 평점/사유/수정안 수집, 피드백 기반 재랭킹 가중/프롬프트 개선, 실험/지표 제공.
 - FastAPI Web UI: 단일 페이지 폼 입력, 스트리밍 응답(옵션), 피드백 제출 UI.
 - 문서 파싱/적재: `docling` 기반 파싱 → 섹션/표/캡션 메타 유지, Confluence DC 단발 수집, `additional_field` LLM 자동 생성.

## 8. 비기능 요구사항
- 성능: P50 응답 ≤ 2.5s, P95 ≤ 5s (검색+생성 합산, 사내 네트워크 기준). 재랭킹 활성화 시 P95 ≤ 6.5s.
- 가용성: 99.5% 월간.
- 보안: MVP에서는 미적용(개발/사내 테스트 환경 한정). 추후 단계에서 SSO/JWT/RBAC 반영.
- 감사/관측: 요청/오류/지연/리콜 지표 로깅 및 대시보드.
- 실험성: A/B 또는 멀티암 밴딧 구성으로 설정 교차검증.
- 확장성: 동시 100 RPS에서 안정 동작, 캐시 적중률 ≥ 30%.

## 9. 성공 지표
- 답변 만족도(내부 설문) ≥ 4.2/5.
- 검색 품질: NDCG@5 ≥ 0.55, MRR@5 ≥ 0.45.
- 근거 클릭률 ≥ 35%.
- 피드백 양의율(좋아요 비율) ≥ 65%.
- 무권한 노출 사고 0건.
- 주간 활성 사용자 수, 세션당 질의 수 증가.

## 10. 마일스톤
- M1: 기본 검색(RRF) + LLM 연결, 최소 기능(2주).
- M2: FastAPI Web UI(질의/결과/피드백) + 청킹 튜닝/관측(로그) 추가(2주).
- M3: 문서 파싱/적재(Confluence 단발 + `docling`) 도입, 품질 개선(프롬프트/재랭킹/압축)(2주).
- M4: 사용자 피드백/실험 도입(2주). 보안/인증은 후속 단계로 분리.

## 11. 의존성과 제약
- Appendix API와의 호환성 유지.
- 사내 인증/키 관리 체계 준수.
- 모델/엔드포인트 가용성(내부 LLM 게이트웨이).
 - RAG insert는 평면 구조(flat) 스키마 고정.
 - Confluence DC API 호출 시 SSL 인증은 비활성화(내부 개발 환경 한정, MVP).

## 12. 오픈 이슈
- 재랭킹 모델(크로스 인코더) 도입 여부와 비용.
- 긴 문서 처리 시 메모리/지연 최적화.
- 멀티모달(이미지/표) 처리 범위.
- 피드백 데이터 개인식별정보(PII) 처리 정책.
- 실험 프레임워크(밴딧 vs A/B) 선택 및 KPI 정의.

## 13. 성능 향상 전략(요약)
- 하이브리드 검색: BM25 + 벡터 동시 호출 후 RRF.
- 다중 쿼리 확장(MQE): LLM 기반 파라프레이즈/용어확장 → 합산.
- PRF: 상위 k 문서 키워드/용어로 재질의.
- MMR/중복제거: 유사도-다양성 균형으로 컨텍스트 구성.
- 크로스 인코더 재랭킹: 상위 50→10 정밀 재정렬.
- 동적 청킹: 섹션/문단/토큰 기반 혼합, 메타 유지.
- 컨텍스트 압축: LLM 요약/핵심문장 추출로 토큰 절감.
- 의미 캐시/응답 캐시: 쿼리 정규화+권한키 기반.
- 임베딩/스케일: 최신 도메인 임베딩, 주기적 리프레시.
- 프롬프트 최적화: 체계적 지시, 근거 인용 강제, 불확실성 처리.
 - 구조 인지 청킹: `docling` 섹션/헤더/표 경계 활용.
