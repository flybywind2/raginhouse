# External API Configuration (compatible with appendix examples)
RAG_BASE_URL=http://localhost:8000
RAG_API_KEY=your_rag_api_key
DEP_TICKET=your_credential_key

# Default configurations
INDEX_NAME=default_index
RETRIEVER=rrf

# LLM Configuration (compatible with internal_llm.py)
OPENAI_API_KEY=your_openai_api_key
LLM_BASE_URL=https://model1.openai.com/v1
MODEL_NAME=llama4 maverick

# Document Processing
DOCLING_ENABLED=true
MAX_CHUNK_SIZE=1024
CHUNK_OVERLAP=128

# Confluence Integration
CONFLUENCE_BASE_URL=https://your-confluence.com
CONFLUENCE_TOKEN=your_confluence_token
CONFLUENCE_VERIFY_SSL=false

# Performance Configuration
REQUEST_TIMEOUT=15.0
MAX_RETRIES=2

# Caching
REDIS_URL=redis://localhost:6379
CACHE_TTL=300

# RAG Optimization Parameters
RRF_K=60
MMR_LAMBDA=0.7
TOKEN_BUDGET=4000
NUM_QUERY_VARIANTS=3
QUERY_SIMILARITY_THRESHOLD=0.85

# Reranking
ENABLE_RERANKING=false
RERANKING_ENDPOINT=
RERANKING_TIMEOUT=2.0
MAX_RERANK_CANDIDATES=50
RERANK_TOP_K=10

# FastAPI Configuration
APP_HOST=0.0.0.0
APP_PORT=8080
DEBUG=false

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Security (MVP: mostly disabled)
ENABLE_AUTH=false
SECRET_KEY=dev-secret-key